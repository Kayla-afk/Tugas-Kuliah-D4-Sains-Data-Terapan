{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1gdrq+lWHNpfkVRBVzPPZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZENhnKb5c5Ae","executionInfo":{"status":"ok","timestamp":1759318816158,"user_tz":-420,"elapsed":18,"user":{"displayName":"Kayla Nuansa Ceria","userId":"12942333872628805677"}},"outputId":"5de1df2c-f601-46ec-b05c-c91f4083165a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset bersih disimpan ke 'ruspini_clean.xlsx'\n","   #   X   Y  CLASS\n","0  1   4  53      1\n","1  2   5  63      1\n","2  3  10  59      1\n","3  4   9  77      1\n","4  5  13  49      1\n","\n","Hasil Cross Validation:\n","Akurasi tiap fold: [1. 1. 1. 1. 1.]\n","Rata-rata akurasi: 1.0\n","Standar deviasi  : 0.0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import cross_val_score, KFold\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","def clean_ruspini_dataset(input_file: str, output_file: str = \"/content/ruspini.xlsx\"):\n","    \"\"\"\n","    Membersihkan dataset Ruspini dari file Excel mentah dan menyimpannya ke file baru.\n","    Hanya mengambil kolom (#, X, Y, CLASS).\n","\n","    Parameters:\n","        input_file (str): Path file input .xlsx (mentah).\n","        output_file (str): Nama file hasil bersih .xlsx.\n","\n","    Returns:\n","        pd.DataFrame: Dataset bersih.\n","    \"\"\"\n","    raw = pd.read_excel(input_file, header=None)\n","\n","    header_rows = raw[raw.apply(lambda row: row.astype(str).str.contains(\"CLASS\").any(), axis=1)].index.tolist()\n","    blocks = []\n","    # Iterate through the header rows to extract data blocks\n","    for i, idx in enumerate(header_rows):\n","        # The data starts from the row after the header\n","        start_row = idx + 1\n","\n","        # The data ends before the next header row, or at the end of the DataFrame if it's the last header\n","        end_row = header_rows[i+1] if i < len(header_rows) - 1 else len(raw)\n","\n","        # Extract the block\n","        temp = raw.iloc[start_row:end_row].copy() # Use .copy() to avoid SettingWithCopyWarning\n","\n","        # Find the columns that contain the headers \"#\", \"X\", \"Y\", \"CLASS\" in the header row (idx)\n","        header_cols = raw.iloc[idx].astype(str).str.findall(r\"#|X|Y|CLASS\").apply(lambda x: x[0] if len(x)>0 else None)\n","        col_indices = {col_name: header_cols[header_cols == col_name].index[0] for col_name in [\"#\", \"X\", \"Y\", \"CLASS\"] if col_name in header_cols.values}\n","\n","        # Select the data using the identified column indices and set column names\n","        if len(col_indices) == 4:\n","            temp = temp[col_indices.values()].copy()\n","            temp.columns = [\"#\", \"X\", \"Y\", \"CLASS\"]\n","        else:\n","            # If not all headers are found in this block, skip or handle as needed\n","            continue\n","\n","        # Drop rows where all relevant columns are NaN (e.g., empty rows between blocks)\n","        temp = temp.dropna(subset=[\"#\", \"X\", \"Y\", \"CLASS\"])\n","        blocks.append(temp)\n","\n","    # Concatenate all blocks\n","    clean_data = pd.concat(blocks, ignore_index=True)\n","\n","    # Convert data types, coercing errors will turn problematic values into NaN\n","    clean_data = clean_data.astype({\"#\": pd.Int64Dtype(), \"X\": pd.Int64Dtype(), \"Y\": pd.Int64Dtype(), \"CLASS\": pd.Int64Dtype()})\n","\n","    # Drop any rows that became NaN after type conversion\n","    clean_data = clean_data.dropna(subset=[\"#\", \"X\", \"Y\", \"CLASS\"])\n","\n","    # Simpan dataset bersih\n","    clean_data.to_excel(output_file, index=False)\n","\n","    return clean_data\n","\n","def knn_cross_validation(data: pd.DataFrame, k_neighbors: int = 5, n_splits: int = 5):\n","    \"\"\"\n","    Melakukan K-NN dengan Cross Validation pada dataset bersih.\n","\n","    Parameters:\n","        data (pd.DataFrame): Dataset bersih dengan kolom X, Y, CLASS.\n","        k_neighbors (int): Jumlah tetangga pada KNN.\n","        n_splits (int): Jumlah fold untuk cross validation.\n","\n","    Returns:\n","        dict: Hasil evaluasi (scores, mean, std).\n","    \"\"\"\n","    # Pisahkan fitur dan label\n","    X = data[[\"X\", \"Y\"]].values\n","    y = data[\"CLASS\"].values\n","\n","    # Inisialisasi KNN\n","    knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n","\n","    # Cross Validation\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    scores = cross_val_score(knn, X, y, cv=kf)\n","\n","    return {\n","        \"scores\": scores,\n","        \"mean_accuracy\": np.mean(scores),\n","        \"std_dev\": np.std(scores)\n","    }\n","\n","if __name__ == \"__main__\":\n","    # 1. Bersihkan dataset\n","    clean_data = clean_ruspini_dataset(\"/content/ruspini.xlsx\", \"ruspini_clean.xlsx\")\n","    print(\"Dataset bersih disimpan ke 'ruspini_clean.xlsx'\")\n","    print(clean_data.head())\n","\n","    # 2. Jalankan KNN + Cross Validation\n","    results = knn_cross_validation(clean_data, k_neighbors=5, n_splits=5)\n","    print(\"\\nHasil Cross Validation:\")\n","    print(\"Akurasi tiap fold:\", results[\"scores\"])\n","    print(\"Rata-rata akurasi:\", results[\"mean_accuracy\"])\n","    print(\"Standar deviasi  :\", results[\"std_dev\"])"]}]}
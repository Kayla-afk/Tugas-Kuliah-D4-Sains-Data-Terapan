{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYkOhGKxztGnoWcipqJpSb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **MODUL 2: MULTILAYER NETWORK**"],"metadata":{"id":"nuwe4-GbbWDs"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"fuUL4AI3NPOP","executionInfo":{"status":"ok","timestamp":1747102775535,"user_tz":-420,"elapsed":79,"user":{"displayName":"Kayla Nuansa Ceria","userId":"12942333872628805677"}}},"outputs":[],"source":["#creating a neural network class\n","class NeuralNetwork:\n","    def __init__(self, x, y):\n","        self.input = x\n","        self.weights1 = np.random.rand(self.input.shape[1], 4)\n","        self.weights2 = np.random.rand(4, 1)\n","        self.y = y\n","        self.output = np.zeros(y.shape)"]},{"cell_type":"code","source":["#Feedforward\n","class NeuralNetwork:\n","    def __init__(self, x, y):\n","        self.input = x\n","        self.weights1 = np.random.rand(self.input.shape[1], 4)\n","        self.weights2 = np.random.rand(4, 1)\n","        self.y = y\n","        self.output = np.zeros(self.y.shape)\n","\n","    def feedforward(self):\n","        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n","        self.output = sigmoid(np.dot(self.layer1, self.weights2))"],"metadata":{"id":"kQbVcMbtTF8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Backpropagation\n","class NeuralNetwork:\n","    def __init__(self, x, y):\n","        self.input = x\n","        self.weights1 = np.random.rand(self.input.shape[1], 4)\n","        self.weights2 = np.random.rand(4, 1)\n","        self.y = y\n","        self.output = np.zeros(self.y.shape)\n","    def feedforward(self):\n","        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n","        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n","    def backprop(self):\n","      #aplication of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n","      d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n","      d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid))\n","      self.weights1 += d_weights1\n","      self.weights2 += d_weights2"],"metadata":{"id":"1LOoRFsmQab1","executionInfo":{"status":"ok","timestamp":1747128300999,"user_tz":-420,"elapsed":29,"user":{"displayName":"Kayla Nuansa Ceria","userId":"12942333872628805677"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#complete python code for doing feedforward and backpropagation\n","import numpy as np\n","import matplotlib\n","\n","inputs = np.array ([[0,1,0],\n","                    [0,1,1],\n","                    [0,0,0],\n","                    [1,0,0],\n","                    [1,1,1],\n","                    [1,0,1]])\n","outputs = np.array([[0], [0],[0], [1], [1], [1]])\n","class NeuralNetwork:\n","  def __init__(self, inputs, outputs):\n","    self.inputs = inputs\n","    self.outputs = outputs\n","    #initialize weights as .50 for simplicity\n","    self.weights = np.array([[.50], [.50], [.50]])\n","    self.error_history = []\n","    self.epoch_list = []\n","  def sigmoid(self, x, deriv=False):\n","    if deriv == True:\n","      return x * (1-x)\n","    return 1 / (1+np.exp(-x))\n","\n","    #data will flow through the neural network\n","    def feed_forward(self):\n","      self.hidden = self.sigmoid(np.dot(self.inputs, self.weights))\n","\n","    #going backwards through the network to update weights\n","    def backpropagation(self):\n","      self.error = self.outputs - self.hidden\n","      delta = self.error * self.sigmoid(self.hidden, deriv=True)\n","      self.weights += np.dot(self.inputs.T, delta)\n","\n","    #train the neural net for 25,000 iterations\n","    def train(self, epochs=25000):\n","      for epoch in range(epochs):\n","        self.feed_forward()\n","        self.backpropagation()\n","        self.error_history.append(np.average(np.abs(self.error)))\n","        self.epoch_list.append(epoch)\n","    #function to predict output on new and unseen input data\n","    def predict(self, new_input):\n","      prediction = self.sigmoid(np.dot(new_input, self.weights))\n","      return prediction\n","\n","#create neural network\n","NN = NeuralNetwork(inputs, outputs)\n","NN.train()\n","\n","#two examples to predict\n","example = np.array([[1, 1, 0]])\n","example_2 = np.array([[0, 1, 1]])\n","print(NN.predict(example), ' - Correct ', example[0][0])\n","print(NN.predict(example_2), ' - Correct ', example_2[0][0])\n","\n","#plot the error over the entire training duration\n","plt.figure(figsize=(15,5))\n","plt.plot(NN.epoch_list, NN.error_history)\n","plt.xlabel('Epoch')\n","plt.ylabel('Error')\n","plt.show()\n","\n","import numpy as np\n","import matplotlib.pylab as plt\n","import tensorflow as tf\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Activation, Dense\n","from tensorflow.keras.optimizers import SGD\n","\n","train_y = np.sqrt((2*train_x**2)+1)\n","\n","#create network\n","inputs = Input(shape=(1,))\n","h_layer = Dense(8, activation='relu')(inputs)\n","h_layer = Dense(4, activation='relu')(h_layer)\n","outputs = Dense(1, activation='linear')(h_layer)\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","#optimizer/update rule\n","sgd = SGD(learning_rate=0.001)\n","#Compile\n","model.compile(optimizer=sgd, loss='mse')\n","# Train the network and save the weights after training\n","model.fit(train_x, train_y, batch_size=20, epochs=10000, verbose=1)\n","model.save_weights('weights.weights.h5')\n","\n","#predict training data\n","predict = model.predict(np.array([26]))\n","print('f(26) = ', predict')\n","\n","predict_y = model.predict(train_x)\n","#draw target\n","plt.plot(train_x, train_y), 'r')\n","plt.plot(train_x, predict_y, 'b')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"IRyd1Mmx9kmc","executionInfo":{"status":"error","timestamp":1747133991996,"user_tz":-420,"elapsed":302,"user":{"displayName":"Kayla Nuansa Ceria","userId":"12942333872628805677"}},"outputId":"53e87c55-1810-427e-bcae-1f132c7d8a0b"},"execution_count":3,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NeuralNetwork' object has no attribute 'train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9a08a0aa1cd6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#create neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#two examples to predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'train'"]}]}]}